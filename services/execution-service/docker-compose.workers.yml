# Distributed Celery Workers and Node-RED

services:
  # Redis (shared by all workers)
  redis:
    image: redis:7-alpine
    container_name: execution-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # PostgreSQL (shared by all workers)
  execution-db:
    image: postgres:15-alpine
    container_name: execution-db
    environment:
      POSTGRES_DB: execution_service
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    ports:
      - "5433:5432"
    volumes:
      - execution_db_data:/var/lib/postgresql/data
      - ./database:/docker-entrypoint-initdb.d
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Execution Worker - Heavy job execution tasks
  execution-worker:
    build:
      context: .
      dockerfile: Dockerfile.execution-worker
    container_name: execution-worker
    environment:
      - DATABASE_URL=postgresql://postgres:postgres@execution-db:5432/execution_service
      - REDIS_URL=redis://redis:6379/0
      - RABBITMQ_URL=amqp://guest:guest@rabbitmq:5672/
      - LOG_LEVEL=INFO
      - CELERY_WORKER_CONCURRENCY=8
      - MAX_CONCURRENT_TARGETS=50
      - CONNECTION_TIMEOUT=30
      - COMMAND_TIMEOUT=600
    depends_on:
      - redis
      - execution-db
    volumes:
      - ./logs:/app/logs
      - /var/run/docker.sock:/var/run/docker.sock  # For container management
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 8G
        reservations:
          cpus: '2.0'
          memory: 4G
    healthcheck:
      test: ["CMD", "celery", "-A", "app.celery_app", "inspect", "ping"]
      interval: 60s
      timeout: 30s
      retries: 3
      start_period: 30s

  # System Worker - Maintenance, cleanup, discovery, health tasks
  system-worker:
    build:
      context: .
      dockerfile: Dockerfile.system-worker
    container_name: system-worker
    environment:
      - DATABASE_URL=postgresql://postgres:postgres@execution-db:5432/execution_service
      - REDIS_URL=redis://redis:6379/0
      - RABBITMQ_URL=amqp://guest:guest@rabbitmq:5672/
      - LOG_LEVEL=INFO
      - CELERY_WORKER_CONCURRENCY=4
      - AUTO_DISCOVERY_NETWORKS=["192.168.1.0/24", "10.0.0.0/24"]
      - DISCOVERY_SCAN_TIMEOUT=30
    depends_on:
      - redis
      - execution-db
    volumes:
      - ./logs:/app/logs
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    healthcheck:
      test: ["CMD", "celery", "-A", "app.celery_app", "inspect", "ping"]
      interval: 60s
      timeout: 30s
      retries: 3
      start_period: 30s

  # Celery Beat Scheduler - Single scheduler for all periodic tasks
  system-scheduler:
    build:
      context: .
      dockerfile: Dockerfile.scheduler
    container_name: system-scheduler
    environment:
      - DATABASE_URL=postgresql://postgres:postgres@execution-db:5432/execution_service
      - REDIS_URL=redis://redis:6379/0
      - RABBITMQ_URL=amqp://guest:guest@rabbitmq:5672/
      - LOG_LEVEL=INFO
    depends_on:
      - redis
      - execution-db
      - execution-worker
      - system-worker
    volumes:
      - ./logs:/app/logs
      - celery_beat_data:/app/celerybeat
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
    healthcheck:
      test: ["CMD", "ps", "aux", "|", "grep", "celery.*beat"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Node-RED - Visual workflow designer
  node-red:
    image: nodered/node-red:3.1.3
    container_name: node-red
    environment:
      - TZ=UTC
      - NODE_RED_ENABLE_PROJECTS=true
      - NODE_RED_ENABLE_SAFE_MODE=false
      - FLOWS=flows.json
    ports:
      - "1880:1880"
    volumes:
      - node_red_data:/data
      - ./nodered/custom-nodes:/usr/src/node-red/node_modules
      - ./logs:/app/logs
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:1880/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Nginx Proxy for Node-RED and API routing
  nginx-proxy:
    image: nginx:alpine
    container_name: execution-nginx-proxy
    ports:
      - "8080:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - node-red
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  redis_data:
    driver: local
  execution_db_data:
    driver: local
  celery_beat_data:
    driver: local
  node_red_data:
    driver: local

networks:
  default:
    name: execution-network
    driver: bridge